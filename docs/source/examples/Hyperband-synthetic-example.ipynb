{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import dask.array as da\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import sklearn\n",
    "\n",
    "import dask_ml\n",
    "from dask_ml.datasets import make_classification\n",
    "from dask_ml.wrappers import Incremental\n",
    "from dask_ml.model_selection import HyperbandCV\n",
    "import dask_searchcv\n",
    "\n",
    "from time import sleep\n",
    "dask_ml.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client, LocalCluster\n",
    "procs, threads = 8, 11\n",
    "num_workers = procs * threads\n",
    "cluster = LocalCluster(n_workers=procs, threads_per_worker=threads)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n, d = int(10e3), int(100)\n",
    "# X, y = make_classification(n_features=d, n_samples=n,\n",
    "#                            chunks=(n // 10, d))\n",
    "# classes = da.unique(y)\n",
    "\n",
    "# kwargs = dict(loss='hinge', penalty='elasticnet',\n",
    "#               max_iter=1.0, warm_start=True)\n",
    "# model = Incremental(SGDClassifier(), **kwargs)\n",
    "# params = {'alpha': np.logspace(-4, 0, num=1000),\n",
    "#           'l1_ratio': stats.uniform(0, 1),\n",
    "#           'average': [True, False]}\n",
    "# partial_fit_kwargs = {'classes': classes}\n",
    "\n",
    "from dask_ml.utils import ConstantFunction\n",
    "model = ConstantFunction()\n",
    "params = {'value': stats.uniform(0, 1)}\n",
    "sleep = 0.1\n",
    "partial_fit_kwargs = {'sleep': sleep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = int(1000), int(200)\n",
    "X, y = make_classification(n_features=d, n_samples=n,\n",
    "                           chunks=(n//10, d))\n",
    "alg = HyperbandCV(model, params, max_iter=81)\n",
    "\n",
    "info = alg.info()\n",
    "\n",
    "train_time = sleep * info['total_partial_fit_calls']\n",
    "best_time = train_time / num_workers\n",
    "print(f\"Fastest possible time = {best_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "alg.fit(X, y, **partial_fit_kwargs)\n",
    "actual_time = time() - start\n",
    "print(f\"Actual time = {actual_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(alg.history_)\n",
    "print(df.bracket.max())\n",
    "print(df.bracket_iter.unique())\n",
    "df.tail()\n",
    "# df[df.mean_test_score > 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair import Chart\n",
    "Chart(df).mark_circle().encode(\n",
    "    x='bracket_iter', row='bracket', y='mean_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
