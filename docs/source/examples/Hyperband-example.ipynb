{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperband\n",
    "Hyperband is useful when limited by computational resources. Some examples cases are when\n",
    "\n",
    "* there are many parameters to search over\n",
    "* models take a long time to train\n",
    "\n",
    "Hyperband does only require *one* input, the computational budget. For more information on this, see the documentation: https://dask-ml.readthedocs.io/en/latest/hyper-parameter-search.html\n",
    "\n",
    "Hyperband is an *adaptive* algorithm: it spends as much time as possible on high-performing models by \"killing\" off the lower portion. More detail in mentioned in the `HyperbandCV` class description: https://dask-ml.readthedocs.io/en/latest/modules/generated/dask_ml.model_selection.GridSearchCV.html#dask_ml.model_selection.HyperbandCV\n",
    "\n",
    "Below, we'll simulate having many parameters to search over by having two parameters. These are the most basic for the sklearn's SGDClassifier, `alpha` and `loss`. These control what objective function we're minimizing and how much regularization is present.\n",
    "\n",
    "Hyperband is very similar to `RandomizedSearchCV` and works best with continuous random variables. We simulate log-uniform random variable with lots of samples: `np.logspace(-4, 1, num=1000)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import dask.array as da\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import sklearn\n",
    "\n",
    "import dask_ml\n",
    "from dask_ml.datasets import make_classification\n",
    "from dask_ml.wrappers import Incremental\n",
    "from dask_ml.model_selection import HyperbandCV\n",
    "from dask_ml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client, LocalCluster\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = int(10e3), int(100)\n",
    "X, y = make_classification(n_features=d, n_samples=n,\n",
    "                           n_informative=d // 10,\n",
    "                           chunks=(n // 10, d))\n",
    "classes = da.unique(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "kwargs = dict(loss='hinge', penalty='elasticnet',\n",
    "              max_iter=1.0, warm_start=True)\n",
    "model = Incremental(SGDClassifier(**kwargs))\n",
    "params = {'alpha': np.logspace(-4, 1, num=1000),\n",
    "          'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = HyperbandCV(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "alg.fit(X_train, y_train, classes=da.unique(y))\n",
    "actual_time = time() - start\n",
    "print(f\"Fitting time = {actual_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import GridSearchCV\n",
    "params = {'alpha': np.logspace(-4, 1, num=10),\n",
    "          'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge']}\n",
    "grid = GridSearchCV(model.estimator, params, return_train_score=True)\n",
    "start = time()\n",
    "grid.fit(X, y)\n",
    "print(\"Grid search time =\", time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_alpha = grid.best_params_['alpha']\n",
    "opt_loss = grid.best_params_['loss']\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for loss in df.param_loss.unique():\n",
    "    show = df[df.param_loss == loss]\n",
    "    show.plot(x='param_alpha', y='mean_test_score',\n",
    "              logx=True, ax=ax,\n",
    "             label=loss)\n",
    "plt.plot(2 * [opt_alpha], plt.ylim(), 'p--',\n",
    "         label=f'Hyperband alpha')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('mean_test_score')\n",
    "print('Hyperband loss function =', opt_loss)\n",
    "plt.savefig('hyperband.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
